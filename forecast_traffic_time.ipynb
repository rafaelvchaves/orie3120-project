{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b0d580-696d-4ba2-8576-71c9587a9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from statsmodels.tsa.holtwinters import Holt, ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490b46e2-d1bc-479d-ab7d-b87696769ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/charlieruan/projects_data/2022/ORIE3120_project/fhvhv/2022/fhvhv_tripdata_2022-02.csv')\n",
    "# filter trips that start or end in unknown location\n",
    "df = df[(df['PULocationID'] < 264) & (df['DOLocationID'] < 264)]\n",
    "df = df[df['hvfhs_license_num']=='HV0003']\n",
    "# Since the most frequent trips are picked up and dropped off in the same location\n",
    "# We will further filter so that the 2 locations are different \n",
    "df = df[df['PULocationID'] != df['DOLocationID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec50a0e-12aa-4918-87f2-24d5dda5de79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48379</th>\n",
       "      <td>231</td>\n",
       "      <td>87</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16268</th>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>3414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30581</th>\n",
       "      <td>148</td>\n",
       "      <td>87</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52545</th>\n",
       "      <td>249</td>\n",
       "      <td>87</td>\n",
       "      <td>2494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29619</th>\n",
       "      <td>144</td>\n",
       "      <td>87</td>\n",
       "      <td>2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43802</th>\n",
       "      <td>211</td>\n",
       "      <td>87</td>\n",
       "      <td>2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22912</th>\n",
       "      <td>114</td>\n",
       "      <td>87</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28156</th>\n",
       "      <td>138</td>\n",
       "      <td>87</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49125</th>\n",
       "      <td>234</td>\n",
       "      <td>87</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48380</th>\n",
       "      <td>231</td>\n",
       "      <td>88</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13668</th>\n",
       "      <td>68</td>\n",
       "      <td>87</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32649</th>\n",
       "      <td>158</td>\n",
       "      <td>87</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33363</th>\n",
       "      <td>161</td>\n",
       "      <td>87</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51841</th>\n",
       "      <td>246</td>\n",
       "      <td>87</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48127</th>\n",
       "      <td>230</td>\n",
       "      <td>87</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35530</th>\n",
       "      <td>170</td>\n",
       "      <td>87</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34113</th>\n",
       "      <td>164</td>\n",
       "      <td>87</td>\n",
       "      <td>1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26753</th>\n",
       "      <td>132</td>\n",
       "      <td>87</td>\n",
       "      <td>1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21730</th>\n",
       "      <td>107</td>\n",
       "      <td>87</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PULocationID  DOLocationID     0\n",
       "48379           231            87  4012\n",
       "16268            79            87  3414\n",
       "30581           148            87  2900\n",
       "52545           249            87  2494\n",
       "29619           144            87  2281\n",
       "43802           211            87  2104\n",
       "22912           114            87  1980\n",
       "1884             13            87  1885\n",
       "28156           138            87  1814\n",
       "49125           234            87  1694\n",
       "48380           231            88  1644\n",
       "13668            68            87  1422\n",
       "32649           158            87  1411\n",
       "33363           161            87  1405\n",
       "51841           246            87  1298\n",
       "48127           230            87  1290\n",
       "35530           170            87  1278\n",
       "34113           164            87  1256\n",
       "26753           132            87  1239\n",
       "21730           107            87  1230"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_freq = df.groupby(['PULocationID', 'DOLocationID']).size()\n",
    "df_freq = pd.DataFrame(trip_freq)\n",
    "df_freq = df_freq.reset_index()\n",
    "# look at trips that end in financial district\n",
    "df_freq_finan = df_freq[(df_freq['DOLocationID'] == 88) | (df_freq['DOLocationID'] == 87)]\n",
    "df_freq_finan = df_freq_finan.sort_values(by=0, ascending=False)\n",
    "df_freq_finan.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44bced9-c5c3-45d5-85a0-f0c3fea9f242",
   "metadata": {},
   "source": [
    "Based on the above dataframe, some intersting trips that we can look at are:\n",
    "- (79, 87) East Village (where most bankers live at, where there are a lot of restaurants)\n",
    "- (249, 87) West Village\n",
    "- (138, 87) Laguardia\n",
    "- (234, 87) Union Square, the furthest in Manhattan so far; also very specific\n",
    "- (164, 87) Midtown South (where other banks are at)\n",
    "- (230, 87) Time Square/Theatre District\n",
    "\n",
    "Can pick two, one close and one far:\n",
    "- (79, 87) East Village, roughly 10-15 minutes drive through FDR\n",
    "- (230, 87) Time Square/Theatre District, 20 minutes when no traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d4d0a0-4be5-47d4-84ac-172dac089789",
   "metadata": {},
   "source": [
    "### Filter, and get the travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de3bcb6-370d-4749-88f8-a306f4209af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUID = 79 # East Village\n",
    "PUID = 230 # Time Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a0afeef-5aae-44e7-80b9-4dc381136d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>2022-02-01 00:14:38</td>\n",
       "      <td>2022-02-01 00:29:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47346</th>\n",
       "      <td>2022-02-01 06:37:12</td>\n",
       "      <td>2022-02-01 07:00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67841</th>\n",
       "      <td>2022-02-01 07:15:14</td>\n",
       "      <td>2022-02-01 07:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145328</th>\n",
       "      <td>2022-02-01 10:18:36</td>\n",
       "      <td>2022-02-01 10:47:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164453</th>\n",
       "      <td>2022-02-01 11:01:07</td>\n",
       "      <td>2022-02-01 11:37:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime    dropoff_datetime\n",
       "6339   2022-02-01 00:14:38 2022-02-01 00:29:57\n",
       "47346  2022-02-01 06:37:12 2022-02-01 07:00:56\n",
       "67841  2022-02-01 07:15:14 2022-02-01 07:44:42\n",
       "145328 2022-02-01 10:18:36 2022-02-01 10:47:41\n",
       "164453 2022-02-01 11:01:07 2022-02-01 11:37:04"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_EV = df[(df['PULocationID']==PUID) & (df['DOLocationID']==87)]\n",
    "df_EV = df_EV[['pickup_datetime', 'dropoff_datetime']]\n",
    "\n",
    "# convert to actual datetime object\n",
    "df_EV['pickup_datetime'] = pd.to_datetime(df_EV['pickup_datetime'])\n",
    "df_EV['dropoff_datetime'] = pd.to_datetime(df_EV['dropoff_datetime'])\n",
    "df_EV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72a82549-9bc1-46e1-9035-60dd9275c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_EV.iterrows():\n",
    "    df_EV.loc[index, 'date'] = row['pickup_datetime'].date()\n",
    "    df_EV.loc[index, 'hr_of_day'] = row['pickup_datetime'].hour\n",
    "    df_EV.loc[index, 'duration_min'] = (row['dropoff_datetime'] - \n",
    "                                        row['pickup_datetime']).total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252a0f57-ac06-4d9e-9c14-fca814f28ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_dur = df_EV.groupby(['date', 'hr_of_day']).mean()\n",
    "df_avg_dur = df_avg_dur.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f991be-3edd-4688-959a-d08059a19ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is some entry that is empty, then we just fill that with the previous duration\n",
    "dates = df_avg_dur.date.unique()\n",
    "hours = np.arange(0, 24)\n",
    "recent_dur = None\n",
    "counter = 0\n",
    "\n",
    "for date in dates:\n",
    "    for hour in hours:\n",
    "        df_cur = df_avg_dur[(df_avg_dur['date']==date) & (df_avg_dur['hr_of_day']==hour)]\n",
    "        if len(df_cur) == 1:\n",
    "            # there is an entry, then update most recent dur\n",
    "            recent_dur = np.array(df_cur.duration_min)[0]\n",
    "        else:\n",
    "            # there is no such entry, we need to fill it in using most recent duration\n",
    "            counter += 1\n",
    "            df_avg_dur.loc[-counter] = [date, hour, recent_dur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4e38e3-ad55-46e1-8c29-bcc8c79a4890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hr_of_day</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>date_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_hr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-01 00:00:00</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.316667</td>\n",
       "      <td>2022-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01 01:00:00</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.316667</td>\n",
       "      <td>2022-02-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01 02:00:00</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.316667</td>\n",
       "      <td>2022-02-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01 03:00:00</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.316667</td>\n",
       "      <td>2022-02-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01 04:00:00</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.316667</td>\n",
       "      <td>2022-02-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28 19:00:00</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.066667</td>\n",
       "      <td>2022-02-28 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28 20:00:00</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.757143</td>\n",
       "      <td>2022-02-28 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28 21:00:00</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>2022-02-28 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28 22:00:00</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.080556</td>\n",
       "      <td>2022-02-28 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28 23:00:00</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.025000</td>\n",
       "      <td>2022-02-28 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  hr_of_day  duration_min             date_hr\n",
       "date_hr                                                                     \n",
       "2022-02-01 00:00:00  2022-02-01        0.0     15.316667 2022-02-01 00:00:00\n",
       "2022-02-01 01:00:00  2022-02-01        1.0     15.316667 2022-02-01 01:00:00\n",
       "2022-02-01 02:00:00  2022-02-01        2.0     15.316667 2022-02-01 02:00:00\n",
       "2022-02-01 03:00:00  2022-02-01        3.0     15.316667 2022-02-01 03:00:00\n",
       "2022-02-01 04:00:00  2022-02-01        4.0     15.316667 2022-02-01 04:00:00\n",
       "...                         ...        ...           ...                 ...\n",
       "2022-02-28 19:00:00  2022-02-28       19.0     29.066667 2022-02-28 19:00:00\n",
       "2022-02-28 20:00:00  2022-02-28       20.0     20.757143 2022-02-28 20:00:00\n",
       "2022-02-28 21:00:00  2022-02-28       21.0     19.510000 2022-02-28 21:00:00\n",
       "2022-02-28 22:00:00  2022-02-28       22.0     20.080556 2022-02-28 22:00:00\n",
       "2022-02-28 23:00:00  2022-02-28       23.0     19.025000 2022-02-28 23:00:00\n",
       "\n",
       "[672 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_dur = df_avg_dur.sort_values(by=['date', 'hr_of_day'])\n",
    "\n",
    "# concatenate hour and date\n",
    "for index, row in df_avg_dur.iterrows():\n",
    "    cur_time = datetime.time(int(row['hr_of_day']), 0)\n",
    "    df_avg_dur.loc[index, 'date_hr'] = datetime.datetime.combine(row['date'], cur_time)\n",
    "df_avg_dur = df_avg_dur.set_index(df_avg_dur['date_hr'])\n",
    "\n",
    "df_avg_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c2215cc-d71b-4cb5-95ce-1446a96e585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_avg_dur[df_avg_dur['date'] <= datetime.date(2022, 2, 20)]\n",
    "df_test = df_avg_dur[df_avg_dur['date'] > datetime.date(2022, 2, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1baf249f-abc8-4bc7-ac97-9c435fdce3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlieruan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/charlieruan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:427: FutureWarning: After 0.13 initialization must be handled at model creation\n",
      "  warnings.warn(\n",
      "/Users/charlieruan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/charlieruan/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:132: FutureWarning: The 'freq' argument in Timestamp is deprecated and will be removed in a future version.\n",
      "  date_key = Timestamp(key, freq=base_index.freq)\n"
     ]
    }
   ],
   "source": [
    "fitted = ExponentialSmoothing(df_train['duration_min'], trend = \"add\", seasonal = \"mul\", \\\n",
    "                              seasonal_periods = 24 * 7).fit()\n",
    "fore = fitted.forecast(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5375be77-8b8d-49d9-af87-88db87c08013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 8), dpi=100)\n",
    "plt.plot(df_avg_dur['duration_min'], label='true values')\n",
    "plt.plot(df_train['date_hr'], fitted.fittedvalues, label='fitted values')\n",
    "fore.plot(label='forecasted')\n",
    "\n",
    "# settings \n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Trip Duration (min)', fontsize=12)\n",
    "plt.xlim(left=datetime.date(2022, 2, 1), right=datetime.date(2022, 2, 28))\n",
    "plt.title('Exponential Smoothing on Trip Duration from Time Square to Financial District', fontsize=16, fontweight='bold')\n",
    "plt.legend(fontsize=10);\n",
    "plt.savefig(\"exp_smooth_trip_duration_timeSquare.png\", dpi=300)\n",
    "plt.clf();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4ab1d91-de26-49fd-9f4e-f028fcbb00c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4016.3962053694145"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = np.sum((fore - df_test['duration_min']).pow(2))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0bee0d-0a28-40cf-81fe-9fe686e6aa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
